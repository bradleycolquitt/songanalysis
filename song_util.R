library(seewave)
library(tuneR)
library(signal)
library(manipulate)
library(reshape2)
library(ggplot2)
library(doMC)
library(foreach)
library(itertools)
library(R.matlab)
library(stringr)
registerDoMC(cores=10)

plot_2dspec = function(wav, peaks=NULL) {
  theme_set(theme_classic())
  manipulate({
    gg = ggspectro(wav, wl=256, ovlp=75) + geom_tile(aes(fill=amplitude)) 
    gg = gg + scale_fill_gradientn(colours=spectro.colors(30), limits=c(-90, 0), na.value="transparent")
    gg = gg + xlim(xmin, xmax) + ylim(2, 15)
    gg
  }, 
  xmax=slider(0, length(wav) / wav@samp.rate, initial=length(wav)/wav@samp.rate),
  xmin=slider(0, length(wav) / wav@samp.rate, initial=0))
}

######## FILTERING/EDITING ########

#' High pass filter Wave object at 1800 Hz
#' @param wav, the input Wave object
filtersong = function(wav, band=1800) {
  return(ffilter(wav, from=band, output="Wave"))
}

#' Moving average smooth Wave object
#' @param wav, the input Wave object
#' @param window, the smoothing window in milliseconds
#' @return Wave object containing smoothed data in left slot 
smoothsong = function(wav, window=0.2) {
  window_length = round(wav@samp.rate * window / 1000)
  data = wav@left
  filt = rep(1, times=window_length) / window_length
  data1 = convolve(data, filt, type="filter")
  return(Wave(data1, samp.rate=wav@samp.rate, bit=wav@bit))
}

######## PROCESSING ########

#' Read in info for wav and processed mat files
#' @param wdir, list or character of working directory containing .wav and .not.mat
#' @param file_ex, pattern searched for by list.files
#' @return data.frame containing file info 
load_mat_info = function(wdir, file_ex = ".mat") {
  files = NULL
  if (length(wdir) > 1) {
    files = unlist(lapply(wdir, list.files, full.names = TRUE, pattern = file_ex))
  } else {
    files = list.files(wdir, full.names = TRUE, pattern = file_ex)
  }  

  files.wav = str_replace(files, ".not.mat", "")
  info = file.info(files.wav)
  info$date = strftime(info$mtime, '%Y-%m-%d')
  info$time = strftime(info$mtime, '%H:%M:%S')
  info$time_h = strftime(info$mtime, '%H')
  info$mat = files
  info$wav = files.wav
  return(info)
}

load_mat = function(file) {
  mat = readMat(file)
  labels = unlist(str_split(mat$labels, ""))
  out = data.frame(onsets=mat$onsets, offsets=mat$offsets, labels=labels)
  out$id = paste(basename(str_replace(file, ".wav.not.mat", "")), 1:nrow(out), sep="-")
  out[,1:2] = out[,1:2] / 1000
  out
}

load_mat_batch = function(info) {
  mat = foreach(row=isplitRows(info, chunkSize=1), .combine="rbind") %do% {
    a = load_mat(row["mat"])
    #a$id = paste(basename(str_replace(row["wav"], ".wav", "")), 1:nrow(a), sep="-")
    a
  }
  #mat$id = 1:nrow(mat)
  return(mat)
}
######## SYLLABLE CLASSIFICATION ########

#' Extract song features from wav file and peaks file generated by evsonganaly
#' @param wav, unfiltered Wave file
#' @param peaks, as generated by load_mat function
#' @return data.frame with song features that classify syllables well 
#'         (durations, wiener entropy, time-to-max amplitude, etc.)
extract_features = function(wav, peaks) {
  wavf = filtersong(wav)
  peaks = peaks[as.numeric(peaks$onsets)>.005,]
  peaks = peaks %>% filter(!labels %in% c(" ", "n"))
  if (nrow(peaks) == 0) return(NULL)
  #peaks$ind = 1:nrow(peaks)
  peaks$onsets.frames = peaks[,"onsets"] * wav@samp.rate
  peaks$offsets.frames = peaks[,"offsets"] * wav@samp.rate
  
  durations = peaks[,"offsets"] - peaks[,"onsets"]
  
  amp = env(wavf, envt="abs", plot=F)
  data = apply(peaks, 1, function(row) {
    amp_window = amp[row["onsets.frames"]:row["offsets.frames"]]
    amplitude = mean(amp_window)
    max_amp = max(amp_window)
    time_to_max = which.max(amp_window)
    time_from_max = length(amp_window) - which.max(amp_window)
    went = wiener_entropy(wavf, band=c(2000, 10000), subregion=c(as.numeric(row["onsets"]), as.numeric(row["offsets"])))
    psd1 = foreach(step=c(.005, .007, .009, .011), .combine="cbind") %do% {
      psd = spec(wavf,  fftw = T, PSD = T, plot=F, at=as.numeric(row["onsets"]) + step,)
      psd
    }
    psd1 = psd1[,c(1, seq(2, ncol(psd1), 2))]
    psd = cbind(psd1[,1], apply(psd1[,2:ncol(psd1)], 1, mean))
    mid = round(nrow(psd)/2)
    psd_ratio = sum(psd[mid:nrow(psd),2]) / sum(psd[1:mid,2])
    max_freq = psd[which.max(psd[,2]),1]
    return(c(amplitude, time_to_max, time_from_max, went, max_freq, psd_ratio, psd[1:128,2]))
  })
  data = t(data)
  colnames(data) = c("amp", "time_to_max", "time_from_max", "went", "max_freq", "psd_ratio", paste("freq", 1:(ncol(data)-6), sep=""))
  data = data.frame(id=peaks$id, labels=peaks$labels, durations, data)
  data$labels = factor(data$labels)
  return(data)
}

extract_features_batch = function(info) {
  data = foreach(row=isplitRows(info, chunkSize=1), .combine="rbind") %dopar% {
    wav = readWave(row[1, "wav"])
    mat = load_mat(row[1, "mat"])
    ex = extract_features(wav, mat)
    ex
  }
  syl_table = table(data$labels)
  data = droplevels(data[!data$labels %in% names(syl_table)[syl_table<(nrow(data) * .05)],])
  data
}

#' Train random forest classifier on syllable labels and song features
#' @param data, song feature file as generated by extract_features
#' @return randomForest object
rf_syllables = function(data) {
  require(randomForest)
  #ind = sample(1:nrow(data), replace = F, size = round(nrow(data)*.80))
  #train = data[ind,]
  #test = data[-ind,]
  #fit.rf = randomForest(labels~., train, xtest = test[,2:ncol(test)], ytest = test[,1], ntree=5000)
  fit.rf = randomForest(labels~., data, ntree=5000)
  return(fit.rf)
}

predict_syllables = function(rf, data) {
  pred = predict(rf, data)  
}

test_rf_sample_size = function(data) {
  ind = sample(1:nrow(data), round(nrow(data)*.8), replace=F)
  train = data[ind,]
  test = data[-ind,]
  test_ind = seq(100, nrow(train), 100)
  rs = mclapply(test_ind, function(x) {
    rf = lapply(1:10, function(x) {
                
      rf = randomForest(labels~., train[sample(1:nrow(train), test_ind, replace=F),], xtest = test[,2:ncol(test)], ytest = test[,1], ntree=5000)
      confusion = rf$confusion
      n = confusion
      off_ind = lower.tri(confusion) | upper.tri(confusion)
      off = sum(confusion[off_ind])
      on = sum(confusion[!off_ind])
      return(off / on)
    })
    mean(unlist(rf))
  }, mc.cores=10)
  rs = unlist(rs)
  return(data.frame(ind = test_ind, error= rs))
}

mclust_syllable_data = function(data, range_to_test=c(4:12), plot=FALSE) {
  pc = prcomp(scale(data))
  pred = predict(pc, data)
  mc = Mclust(pred, G=range_to_test)
  if (plot) {
    plot(mc)
  }
  return(mc)
  #return(data.frame(called = mc$classification, data))
}

plot_clustering_3d = function(data) {
  require(plotly)
  #x_vec = data$PC1
  #y_vec = data$PC2
  #z_vec = data$PC3
  plot_ly(data, x = PC1, 
          y = PC2, 
          z = PC3, 
          color = km8,
          size = PC4,
          type = "scatter3d", 
          mode = "markers", 
          filename="r-docs/3d-scatter")
#   data <- list(
#     x = x_vec,
#     y = x_vec,
#     z = z_vec,
#     type = "points")
}
plot_classfied_syllable = function(peaks) {
  #peaks_s = split(peaks, peaks$called)
  peaks_s = peaks %>% group_by(called) %>% do(sample_n(., 10))
  peaks_s1 = split(peaks_s, peaks_s$called)
  plots = lapply(peaks_s1, function(d)  {
  })
  
  return(peaks_s)
}

plot_spectro = function(wav, subregion=NULL, wl=512, overlap=50) {
  duration = NULL
  input = inputw(wav)
  wave = input$w
  f = input$f
  if (!is.null(subregion)) {
    duration = diff(subregion)
  } else {
    duration = duration(wav)
  }
  
  sf = subregion * f
  print(sf)
  n = nrow(wave)
  if (!is.null(subregion)) {
    step <- seq(sf[1], sf[2] - wl, wl - (overlap * wl/100))
  } else {
    step <- seq(1, n - wl, wl - (overlap * wl/100))
  }
  z = stft(wave = wave, f = f, wl = wl, zp = 0, step = step, 
            wn = "hanning", fftw = TRUE, scale = FALSE, complex = FALSE)
  
  zm = melt(z)
  return(z)
  
}



######## PEAK ANALYSIS ########

#' Find amplitude peaks in wav file
#' @param wav, the input Wave object
#' @param min_duration, minimum duration required for peak calling
#' @param max_gap, maximum distance (in ms) between peaks before merging
#' @param thresh, threshold for peak definition, defined as fraction of max amplitude
#' @return data.frame containing peak starts (col1) and stops (col2) defined in seconds
findpeaks = function(wav, min_duration=50, max_gap=75, thresh=0.1) {
  samp_rate = wav@samp.rate
  min_duration = min_duration * samp_rate / 1000 
  max_gap = max_gap * samp_rate / 1000
  wav_env = env(wav, plot=F)
  max_val = max(wav_env)
  wav_env = wav_env / max_val
  above_thresh_ind = which(wav_env[,1]>thresh) 
  thresh_diff = which(diff(above_thresh_ind)>max_gap)
  df = data.frame(ins=c(above_thresh_ind[1], 
                           above_thresh_ind[thresh_diff+1]),
                     outs=c(above_thresh_ind[thresh_diff], 
                            above_thresh_ind[length(above_thresh_ind)]))
  return(df[(df[,2] - df[,1])>min_duration,] / samp_rate)
  if ((df[,2] - df[,1]) == 0) return(NULL)
  return (df / samp_rate)
}

#' Find amplitude peaks in wav file, using absolute amplitude threshold
#' @param wav, the input Wave object
#' @param min_duration, minimum duration required for peak calling
#' @param max_gap, maximum distance (in ms) between peaks before merging
#' @param thresh, threshold for peak definition, defined as fraction of max amplitude
#' @return data.frame containing peak starts (col1) and stops (col2) defined in seconds
findpeaks_abs = function(wav, min_duration=50, max_gap=75, thresh=1E7) {
  samp_rate = wav@samp.rate
  min_duration = min_duration * samp_rate / 1000 
  max_gap = max_gap * samp_rate / 1000
  wav_env = env(wav, envt = "abs", plot=F)
  #max_val = max(wav_env)
  #wav_env = wav_env / max_val
  above_thresh_ind = which(wav_env[,1]>thresh) 
  if (length(above_thresh_ind) == 0) return(data.frame())
  thresh_diff = which(diff(above_thresh_ind)>max_gap)
  df = data.frame(ins=c(above_thresh_ind[1], 
                        above_thresh_ind[thresh_diff+1]),
                  outs=c(above_thresh_ind[thresh_diff], 
                         above_thresh_ind[length(above_thresh_ind)]))
  return(df[(df[,2] - df[,1])>min_duration,] / samp_rate)
  if ((df[,2] - df[,1]) == 0) return(data.frame())
  return (df / samp_rate)
}


#' Find frequency peaks in PSD
#' @param wav, the input Wave object
#' @param min_size, minimum band size of peak
#' @param max_gap, maximum distance (in Hz) between peaks before merging
#' @param thresh, threshold for peak definition, defined as fraction of max amplitude
#' @return data.frame containing peak starts (col1) and stops (col2) defined in seconds
findpeaks_freq = function(mat, min_value=2, min_size=50, max_gap=100, thresh=0.1) {
  mat = mat[mat[,1]>min_value,]
  max_val = max(mat[,2])
  mat[,2] = mat[,2] / max_val
  scale_val = (mat[2,1] - mat[1,1]) * 1000
  above_thresh_ind = which(mat[,2]>thresh) 
  thresh_diff = which(diff(above_thresh_ind)>(max_gap/scale_val))
  df = data.frame(ins=c(mat[above_thresh_ind[1],1], 
                        mat[above_thresh_ind[thresh_diff+1],1]),
                  outs=c(mat[above_thresh_ind[thresh_diff],1], 
                         mat[above_thresh_ind[length(above_thresh_ind)],1]))
  return(df[(df[,2] - df[,1])>min_size,])
}

#' Find temporal distance between peaks
#' @param peaks, data frame as outputted by findeaks, col1 is peak starts, col2 is peak stops
#' @return vector of interpeak distances
peak_dist = function(peaks) {
  if (nrow(peaks)<2) return(NA)
  dists = vector("numeric", nrow(peaks)-1)
  for (i in 1:(nrow(peaks)-1)) {
    dists[i] = peaks[i+1,1] - peaks[i,2]
  }
  return(dists)
}

interpeak_midpoint = function(peaks) {
  if (nrow(peaks)<2) return(NA)
  dists = vector("numeric", nrow(peaks)-1)
  for (i in 1:(nrow(peaks)-1)) {
    dists[i] = sum(peaks[i+1,1] + peaks[i,2]) / 2
  }
  return(dists)
}

plot_peaks = function(peaks, yval=-1E7, ...) {
  apply(peaks, 1, function(peak) {
    segments(peak[1], yval, peak[2], yval, ...)
  })
}

######## WIENER ENTROPY ########
#' Calculate Wiener entropy of given frequency band in Wave object
#' @param wav, Wave object
#' @param band, selected frequency band
#' @param subregion, vector giving start and end of wav subregion to analyze, in seconds
#' @references https://en.wikipedia.org/wiki/Spectral_flatness
#' @return scalar, calculated Weiner entropy
wiener_entropy = function(wav, band=NULL, subregion=NULL) {
  psd = NULL
  if (!is.null(subregion)) {
    psd = spec(wav, wl=512, plot=F, PSD=T, from=subregion[1], to=subregion[2])
  } else {
    psd = spec(wav, wl=512, plot=F, PSD=T)
  }
  
  psd[,1] = 1000 * psd[,1] # convert to Hertz from kHertz
  if (is.null(band)) band = c(1, nrow(psd))
  psd1 = psd[psd[,1]>band[1] & psd[,1]<band[2],]
  res = exp(mean(log(psd1[,2]))) / mean(psd1[,2])
  return(res)
}

wiener_entropy_var = function(wav, window=16, overlap=50, band=NULL, subregion=NULL) {
  subregion = subregion * 1000
  steps = seq(0, subregion[2]-subregion[1], window * overlap / 100)
  wav_duration = duration(wav)
  res = sapply(steps, function(step) {
    subregion2 = subregion 
    subregion2[1] = subregion[1] + step
    subregion2[2] = subregion2[1] + window
    subregion2 = subregion2 / 1000
    if (subregion2[2] > wav_duration) return(NA)
    wiener_entropy(wav, band=band, subregion=subregion2)
  })
  res = na.omit(res)
  var(res)
}

#' Calculate Weiner entropy of given frequency band in PSD
#' @param psd, PSD as output from spec(PSD=T)
#' @param band, selected frequency band
#' @references https://en.wikipedia.org/wiki/Spectral_flatness
#' @return scalar, calculated Weiner entropy
weiner_entropy_psd = function(psd, region=c(6,8)) {
  psd1 = psd[psd[,1]>region[1] & psd[,1]<region[2],]
  res = exp(mean(log(psd1[,2]))) / mean(psd1[,2])
  return(res)
}

#' Calculate Weiner entropy and Wiener entropy variance given info file
#' as returned by load_mat_file
#' @param info, info file as returned by load_mat_file
#' @param band, selected frequency band
#' @return data.frame, given info file supplmented with calculated values
#'   \item{went}{wiener entropy}
#'   \item{wev}{variance of wiener entropy across syllable}
wiener_stats = function(info, band=c(2000, 10000)) {
  d = foreach(row=isplitRows(info, chunkSize=1)) %dopar% {
    out = load_mat(row["mat"])
    wav = readWave(row[1, "wav"])
    out = out %>% rowwise() %>% mutate(went=log2(wiener_entropy(wav, band=band, subregion=c(onsets, offsets))), 
                                       wev=wiener_entropy_var(wav, band=band, subregion=c(onsets, offsets)))
    out$mat = row[1, "mat"]
    out
  }
  do.call(rbind, d)
}

######### SONG FINDERS ########
#' Classify Wave object as song or not song
#'     First filters for small Weiner entropy values within given band
#'     Next filters for small interpeak distances
#' @param wav, Wave object
#' @param band, selected frequency band
#' @param wein_thresh, maximum allowed Wiener entropy in frequency band
#' @param dist_thresh, maximum interpeak distance allowed
#' @return logical, song or not song
songfinder = function(wav, band=c(5000,7000), 
                      wein_thresh=0.4, 
                      dist_thresh = 0.06,
                      min_duration = 1000) {
  wav = filtersong(wav)
  wein = wiener_entropy(wav, band=band)
  if (wein > wein_thresh) {
    return(FALSE)
  } 
  peaks = findpeaks(wav, min_duration=min_duration, max_gap=200, thresh=0.05) 
  return(nrow(peaks) > 0)
}

songfinder2 = function(wav, max_gap = 10, min_duration = 15, thresh=0.2, min_num_peaks = 5) {
  wav = filtersong(wav)
  peaks = findpeaks_abs(wav, min_duration=min_duration, max_gap=max_gap, thresh=thresh)
  return(nrow(peaks) / duration(wav) > min_num_peaks)
}

songfinder_psd = function(psd, 
                          band=c(5,8), 
                          wein_thresh=0.45) {
  wein = weiner_entropy_psd(psd, region=band)
  return(wein<wein_thresh)
}

######## Cepstrum ########
format_cepstrum = function(data) {
  wav_cep_form = melt(data$amp)
  colnames(wav_cep_form) = c("time", "quef", "amp")
  wav_cep_form$time = data$time
  wav_cep_form$quef = rep(data$quef, each=length(data$time))
  return(wav_cep_form)
}

#' Calcualte dynamic cepstrum of wav file 
#' @param Wave object
#' @return cepstrum as dataframe: 1:time, 2:quef, 3:amp
compute_cepstrum_time = function(wav) {
  wav_cep = cepstro(wav, wl=256, ovlp=50)
  return(format_cepstrum(wav_cep))
}

#' Calculate derivative of dynamic cepstrum using least-square approximation
#' @param Wave object
#' @param w, window size
#' @return delta cepstrum as data.frame: 1:time, 2:quef, 3: local derivative
delta_cepstrum = function(wav, w=10, region=NULL) {
  wav_cep = NULL
  if (is.null(region)) {
    wav_cep = cepstro(wav, wl=512, ovlp=50, collevels = seq(0, .01, .001), ylim=c(0, 1) )
  } else {
    wav_cep = cepstro(wav, wl=512, ovlp=50, from=region[1], to=region[2])
  }
  wav_cepf = format_cepstrum(wav_cep)
  wav_cep_mat = wav_cep$amp
  delta_cep = matrix(nrow=(nrow(wav_cep_mat) - (2*w)), ncol=ncol(wav_cep_mat))
  inds = seq(-1*w, w)
  
  #### loop through rows of wav_cep
  norm_factor = inds %*% inds
  for (i in 1:nrow(delta_cep)) {
      delta_cep[i,] = t(inds) %*% wav_cep_mat[(i+w + inds),]
  }
  delta_cep = delta_cep / norm_factor[1,1]
  
  delta_cep_form = melt(delta_cep)
  colnames(delta_cep_form) = c("time", "quef", "amp")
  delta_cep_form$time = wav_cep$time[(w+1):(nrow(wav_cep_mat) - w)]
  delta_cep_form$quef = rep(wav_cep$quef, each=nrow(delta_cep))
  return(delta_cep_form)
}

ggplot_cepstrum = function(data) {
  limits = c(min(data$amp), quantile(data$amp, probs=.99))
  gg = ggplot(data, aes(time, quef, fill=amp)) +  geom_tile() + scale_fill_gradient(limits=limits)
  gg = gg + ylim(0, .7)
  return(gg) 
}

######## Fundamental frequency ########
calc_ff = function(wav, peaks) {
  psd = apply(peaks, 1, function(x) spec(wav, PSD=T, from=x[1], to=x[2], plot=F))
  psd_peaks = lapply(psd, function(data) {
    total_power = sum(data[,2])
    d = findpeaks_freq(data, min_size=0)
    d %>% rowwise() %>% summarize(ins=ins, 
                                  outs=outs, 
                                  prop=sum(data[data[,1]>ins & data[,1]<outs,2])/total_power)
  })
  return(psd_peaks)
}

#' Calculate fundamental frequency by averaging harmonics
#' @param wav, input Wave file
#' @param mat, data.frame containing onsets, offsets, and label as generated by load_mat
#' @return mat file supplemented with calculated fundamental frequency
calc_ff2 = function(wav, mat) {
  psd = apply(mat, 1, function(x) spec(wav, PSD=T, from=as.numeric(x["onsets"]), to=as.numeric(x["offsets"]), plot=F))
  freqs = unlist(lapply(psd, function(data) {
    d = findpeaks_freq(data, min_value=2, max_gap=1000, min_size=0, thresh=.1)
    d_mean = apply(d, 1, mean)
    d_mean = data.frame(ind=1:length(d_mean), d_mean=d_mean)
    d_freq = apply(d_mean, 1, function(x) x[2]/x[1])
    mean(d_freq)
  }))
  return(cbind(mat, freqs)) 
}

calc_freq_rolling = function(wav, step = 4, duration = 8, band=NULL, subregion=NULL) {
  steps = seq(0, subregion[2]-subregion[1], step)
  res = sapply(steps, function(step) {
    calc_freq(wav, offset=step, duration=duration, band=band, subregion=subregion)
  })
  mean(res)
}

calc_freq = function(wav, offset=10, duration=8, band=NULL, subregion=NULL) {
  psd = NULL
  if (!is.null(subregion)) {
    from = subregion[1] + offset
    to = from + duration
    psd = spec(wav, wl=512, norm=F, plot=F, PSD=T, from=(from / 1000), to=(to / 1000))
  } else {
    stop("Please specify subregion!")
  }
 
  psd[,1] = 1000 * psd[,1] # convert to Hertz from kHertz
  if (is.null(band)) band = c(1, nrow(psd))
  psd1 = psd[psd[,1]>band[1] & psd[,1]<band[2],]
  colnames(psd1) = c("freq", "power")
  psd1 = as.data.frame(psd1)
  psd1$onsets = subregion[1]
  psd1$offsets = subregion[2]
  #return(as.data.frame(psd1))
  return(psd1[which.max(psd1[,2]),1])
}

compute_class = function(res, trues) {
  tp = vector("numeric", 4)
  for(i in 1:nrow(trues)) {
    m = match(trues[i,1], res[,1])
    if (trues[i,2] & res[m,2]) { #TP
      tp[1] = tp[1] + 1
    } else if (trues[i,2] & !res[m,2]) { #FN
      tp[2] = tp[2] + 1
    } else if (!trues[i,2] & res[m,2]) { #FP
      tp[3] = tp[3] + 1
    } else if (!trues[i,2] & !res[m,2]) { #TN
      tp[4] = tp[4] +1
    }
  }
  names(tp) = c("TP", "FN", "FP", "TN")
  return(tp)
}

######## SEQUENCING ########
syllable_transition = function(mat) {
  d.labels = unlist(lapply(mat, function(x) as.character(x$labels)))
  label_list = lapply(d.labels, function(x) unlist(str_split(x, "")))
  label_list_cat = unlist(label_list)

  totals = table(label_list_cat)
  labels = names(totals)
  
  labels2 = c("start", labels, "end")
  counts = matrix(0, nrow=length(labels2), ncol=length(labels2), dimnames=list(labels2, labels2))
  
  for (i in 1:length(label_list)) {
    curr = label_list[[i]]
    counts["start", curr[1]] = counts["start", curr[1]] + 1
    for (j in 1:(length(curr)-1)) {
      counts[curr[j],curr[j+1]] = counts[curr[j],curr[j+1]] + 1
    }
    counts[curr[length(curr)], "end"] = counts[curr[length(curr)], "end"] + 1
  }
  return(counts)
}

#' Calculate repeat lengths by bout
#' @param data, info file as returned from load_mat_info
#' @return data.frame
#'   \item{lengths}{length as from rle}
#'   \item{values}{repeated syllable}
#'   \item{mat}{original .not.mat file}
repeat_lengths = function(data) {
  require(foreach)
  require(itertools)
  d = foreach(row=isplitRows(data, chunkSize=1)) %dopar% {
    mat = readMat(row["mat"])
    labels = as.character(mat$labels)
    labels1 = unlist(str_split(labels, ""))
    rles = rle(labels1)
    rd = data.frame(lengths=rles$lengths, values=rles$values, mat=row["mat"])
    rd = rd[rd$values %in% select,]
    rd
  }
  do.call(rbind, d)
}

mean_transition_entropy_long = function(long_data) {
  mean_transition_entropy(acast(long_data, From~To))
}

mean_transition_entropy = function(mat) {
  res = apply(mat, 1, function(x) {
    y = x[x>0]
    sum(y * log2(y))
    #sapply(x, function(y) y * log2(y))
  })
  data.frame(transition_entropy = -1 * sum(res))
}


